{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Citation Needed? Automatically Detecting Sentences from Computing Research Papers that Need Citations\n",
    "Author: Nicholas Vincent, Northwestern University\n",
    "\n",
    "email: nickvincent@u.northwestern.edu | lab I work in: [www.psagroup.org](http://www.psagroup.org) | personal website: [www.nickmvincent.com](http://www.nickmvincent.com)\n",
    "\n",
    "Prof. Doug Downey's EECS349 course, final project\n",
    "\n",
    "## Abstract: \n",
    "The scientific paper is the primary artifact produced by scientists of every discipline. Within a scientific paper, citations are incredibly valuable: they help connect a paper to the surrounding literature, provide evidence for claims, and empower a single PDF (often with less than 10 pages) to “stand on the shoulders of giants” by referencing prior work. However, language is ambiguous, and it may not always be trivial to decide whether a certain sentence should include a citation or not.  Therefore, it may be valuable for an author or reviewer to be able to quickly identify whether a sentence should include a citation or not. We implement and test a variety of machine learning classifiers that attempt to solve this task.\n",
    "\n",
    "In this work, we explore a variety of approaches to classification,  (1) using bag-of-words vectorization alongside textual metadata with traditional classification techniques (Naive Bayes Classifier, Decision Trees, Support Vector Classifier, etc.) and (2) using character-level features and word embeddings with a deep learning techniques (recurrent neural networks, long-short term memory). Using a dataset with 6022 examples (85% negative), we see that support vector machine approaches provide a good balance of performance and quick training (reaching X AUROC with very quick training). Finally, using a larger dataset with 32,228 examples, we find that after tuning hyperparameters we can train a classifer with 85% recall and 40% precision (accuracy is 89%). This performance should be adequate to make this classifier useful as a \"machine assistant\" for authors or reviewers of academic papers.\n",
    "\n",
    "## Organization of this Notebook\n",
    "The main content of this notebook is organized based on the project guidelines for EECS349. At the end of the notebook is an appendix which goes into greater details about project details that are not specifically related to machine learning (e.g. details about the data cleaning, various examples of our dataset).\n",
    "\n",
    "The following sections are:\n",
    "1. Methods: Dataset\n",
    "2. Methods: Overview of Features and Classification Approaches\n",
    "3. Results\n",
    "4. Future Work\n",
    "\n",
    "An [appendix](/appendix) is included in a separate page. While not part of the official project submission, the appendix includes a variety of minor details that may be interesting and helpful (or not) to readers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Methods: Dataset\n",
    "#### Data Aquisition\n",
    "We generated all training and test data by downloading computing papers as PDF files and converting them to text (detailed below). Each text file was processed so as to split the text into sentences, identify all the sentences with citations, and then strip out the evidence of the citations (e.g. bracketed numbers like \"[1]\") so the data could be fairly for training. The full data pre-processing steps are explained in the Appendix.\n",
    "\n",
    "We built two datasets for developing and testing, a small dataset and a larger dataset.\n",
    "\n",
    "First we used a small dataset composed of X papers. This dataset included 6022 different sentences and 11% (X) had citations. The papers for this dataset came exclusively from the PSA Research Group (the author's research lab), so we use this data when referring to example sentences. We refer to this dataset as the \"psa_research dataset\" in code and file organization.\n",
    "\n",
    "The second dataset was produced by downloading the full Proceedings of the 2018 CHI Conference on Human Factors in Computing Systems (CHI 2018), made available through the [ACM Digital Library]() (CITE) From this set of over 600 papers, we used 100 papers, which allowed the full training and testing process could be performed on a single laptop.\n",
    "\n",
    "\n",
    "## Methods: Overview of Features and Classification Approaches Used\n",
    "\n",
    "### Initial Approach\n",
    "For our first set of classification approaches, we followed a simple strategy to turn sentences into features. We vectorized each sentence using a term frequency-inverse document frequency (Tf-Idf) approach, and then computed additional \"hand-crafted\" features to account for some aspects of text that are not captured by word counting: number of characters in the sentence and boolean variables indicating whether each sentence has any digit characters, has a comma character, has a quote character, and has an uppercase character after the first character.\n",
    "\n",
    "Tf-Idf details: For the large dataset, we limited the bag-of-words vocabulary size to the 10,000 most frequent words to avoid memory issues. For all datasets, we included stop-words (as removing them just lowered performance) and stripped accents.\n",
    "\n",
    "Then, we performed a variety of runs with statistical test feathe ture selection to reduce dimensionality of our feature space (sklearn's SelectKBest with ANOVA F-value, see http://scikit-learn.org/stable/modules/generated/sklearn.feature_selection.f_classif.html#sklearn.feature_selection.f_classif). We tried reducing the max number of features to:\n",
    "50,100,500,1000,2000,3000,4000,5000\n",
    "\n",
    "Using these sets of features, we tested a variety of classifiers (using sklearn implementations, with default parameters unless otherwise noted).\n",
    "1. Logistic Regression (using C Values of 0.1, 1, and 10)\n",
    "2. Linear Support Vector Classifier (using C values of 0.1, 1, and 10)\n",
    "3. Decision Tree\n",
    "4. Gaussian Naive Bayes\n",
    "5. K-Nearest Neighbors (3 neighbors)\n",
    "\n",
    "### Deep Learning\n",
    "We tested two different deep learning approaches for classification as well. Both were implemented using Tensorflow.\n",
    "\n",
    "First, we tried to use a character-level RNN (features were character embeddings) trained for language modeling to perform classifications by adding our labels as tokens at the end of the sentence (e.g. \"this is negative example.@@0 And this is a positive examples.@@1\". See code for more details). and predicted these tokens. The code for this implementation was a modified fork of this MIT-licensed Github repo: https://github.com/crazydonkey200/tensorflow-char-rnn.\n",
    "\n",
    "Second, we trained a simple neural network using Tensorflow's DNNClassifier Estimator. For this classifier, we used the Wiki-word word embeddings, which are pre-trained on the Wikipedia corpus and available with Tensorflow. We tried a few network architectures with 1, 2, and 3 hidden layers. The code for this implementation was a modified version of this CC-3.0 tutorial in the Tensorflow docs: https://www.tensorflow.org/tutorials/text_classification_with_tf_hub.\n",
    "\n",
    "### A note on software and hardware used\n",
    "As mentioned above, all our deep learning implementations used Tensorflow and all other machine learning implementations used sklearn. While we used multiple machines (including Google Cloud Platform) throughout experiments, all our reported results were run from the same machine, a Dell XPS 13 64-bit Windows machine with Intel i7-6560U CPU @ 2.20 GHZ and no GPU. This allowed us to directly compare the time taken of various methods.\n",
    "\n",
    "## Results\n",
    "### Metrics and other Considerations\n",
    "For all our experiments, we decided to focus on performance metrics beyond accuracy, especially given the imbalanced class labels. Specifically, we chose to use area under the receiver operator characteristic curve (AUROC) when initially comparing models with the small dataset (as we were interested in having a model with strong discriminative power), and then to focus on the precision-recall curves for the large dataset to try to achieve a good precision-recall balance for users. The use case we considered was an academic who is writing a paper or reviewing a paper and wants to quickly use our tool to check for any sentences that might need citations. Under this model, the user likely wants to emphasize recall over precision: because most sentences do not have citations, if the model identifies all the sentences that do have citations, the user can quickly eliminate the false positives with their human judgment. Therefore, we decided to aim for a model that had the best precision when recall was over 80%.\n",
    "\n",
    "Given that academics are often very busy, come from a variety of different fields and disciplines, often like to run their own software, and often work with limited computing resources, we also wanted to emphasize models that train quickly, test quickly, and run on a laptop, so that users could realistically train their own personal model. That being said, we still did consider the performance of slower and costlier approaches (e.g. deep learning, nearest neighbors) in case performance was vastly improved.\n",
    "\n",
    "### Comparing models performance for the `psa_research` dataset\n",
    "Below, Figure 1 shows the AUROC for our experiments on the smaller `psa_research` dataset. We found that SVM, logistic regression, and deep neural network classifer, all performed well (although the neural net took orders of magnitude more time to train). The best classifer was a linear SVM classifer with C=0.1 and the best 2000 features selected. Based on these results, we eliminated Naive Bayes, Decision Tree, and Nearest Neighbor classifer.\n",
    "\n",
    "### Precision-recall with the `chi_2018` dataset\n",
    "\n",
    "We treated this \n",
    "We found that...\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Future Work\n",
    "While we focused on testing models that were small and quick to train, an interesting next step would be to try to build an extremely general model, incorporating text from across academic disciplines. This would require substantially more infrastructure and resources. It would be interesting to see how deep learning methods compare to other methods when using orders of magnitude more data (and, by extension less similar data).\n",
    "\n",
    "Additionally, if user tests suggest that performance of our classifers are unsatisfactory, it may be possible to tweak our implementation to improve overall performance, perhaps through additional hand-crafted features designed by academics familiar with a particular fields writing trends, or through a more comprehensive hyperparameter search."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Appendix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0    211017\n",
       "1.0     31422\n",
       "Name: has_citation, dtype: int64"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv('all_labeled_sentences.csv', encoding='utf8')\n",
    "df['has_citation'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===\n",
      "Example sentences without citations:\n",
      "(no citation) how to join these lumber boards is essential to woodworking.\n",
      "(no citation) Paper 309\r",
      "\r",
      "\r\n",
      "\r",
      "\r",
      "\r\n",
      "Page 1\r",
      "\r",
      "\r\n",
      "\r",
      "\r",
      "\r\n",
      "\f",
      "CHI 2018 Paper\r",
      "\r",
      "\r\n",
      "\r",
      "\r",
      "\r\n",
      "CHI 2018, April 21­26, 2018, Montréal, QC, Canada\r",
      "\r",
      "\r\n",
      "\r",
      "\r",
      "\r\n",
      "Guided by this prior work, we conducted a study to answer this overarching question: How does socioeconomic context shape caregivers' perceptions and use of current PA tracking tools?\n",
      "(no citation) Our system was more accurate on fully incorrect SPSes (57% were \"Accurate\") than partially incorrect SPSes (36% were \"Accurate\").\n",
      "(no citation) 15.00 DOI: https://doi.org/10.1145/3173574.3173656\r",
      "\r",
      "\r\n",
      "\r",
      "\r",
      "\r\n",
      "INTRODUCTION Electronic textile technology enables people to create expressive, interactive, and functional textile artifacts for both playful and serious applications.\n",
      "(no citation) In the long-answer category, recordings coded as Definition made up 7.63%.\n",
      "(no citation) Clickstream and in-video dropout data are passively collected in that the data is naturally collected regardless of learners' intention.\n",
      "(no citation) Our results (Tab.\n",
      "(no citation) Publication date: January 2017.\n",
      "(no citation) Paper 156\r",
      "\r",
      "\r\n",
      "\r",
      "\r",
      "\r\n",
      "Page 3\r",
      "\r",
      "\r\n",
      "\r",
      "\r",
      "\r\n",
      "\f",
      "CHI 2018 Paper\r",
      "\r",
      "\r\n",
      "\r",
      "\r",
      "\r\n",
      "CHI 2018, April 21­26, 2018, Montréal, QC, Canada\r",
      "\r",
      "\r\n",
      "\r",
      "\r",
      "\r\n",
      "Figure 2.\n",
      "(no citation) are more correlated with total-views than others (obnoxious, unconvincing, confusing etc.).\n",
      "(no citation) [u]\r",
      "\r",
      "\r\n",
      "However, though commenters often presented this as common sense, there was also recognition that understanding specific privacy practices requires research.\n",
      "(no citation) (P13)\r",
      "\r",
      "\r\n",
      "Finally, the theme of independence was mentioned by four participants--that is, enabling tasks that had previously required assistance from others.\n",
      "(no citation) HCI researchers often engage in multiple preliminary or pilot studies in which conditions and methods are progressively tuned to create sensitive experiments that reliably reveal significant effects.\n",
      "(no citation) Explicit instructions were given to \"feel the sides of the buildings all the way to the base to find the doors\".\n",
      "(no citation) ACM Classification Keywords H.5.m.\n",
      "(no citation) We develop an application using HindSight to warn cyclists of approaching vehicles outside their field of view and evaluate it in an exploratory study with 15 users.\n",
      "(no citation) Based on this framework, we implement InfoNice as a Power BI custom visual called \"Infographic Designer\".\n",
      "(no citation) The rendering rule for pitch also behaves similarly.\n",
      "(no citation) When riding Ava, limitations of the Körper are easily apparent: after riding any bike for longer periods of time, the legs get tired.\n",
      "(no citation) CONCLUSION In this paper, we proposed a method called Ohmic-Touch that extends the modality of touch inputs using the electric resistance on commercial capacitive touch surfaces.\n",
      "(no citation) \"Can you?\"\n",
      "(no citation) During reflection, they provided a variety of viewpoints on what they felt about apps' data collection activities and the companies behind them.\n",
      "(no citation) Do not place input controls on the bottom right.\n",
      "(no citation) We apply this training to our access to large and varied datasets.\n",
      "(no citation) After the training tasks, participants did three 5-minute tasks that corresponded to the three conditions (Control, Content-similar, and Curated).\n",
      "(no citation) Our application software was developed with Unity.\n",
      "(no citation) Mapping patterns to stories was con-\r",
      "\r",
      "\r\n",
      "\r",
      "\r",
      "\r\n",
      "sidered considered less simple but very much possible with\r",
      "\r",
      "\r\n",
      "\r",
      "\r",
      "\r\n",
      "an average rating of 6.8 1\r",
      "\r",
      "\r\n",
      "\r",
      "\r",
      "\r\n",
      "10.\n",
      "(no citation) At Farxad center, Nafiso (F13) drew a static scene depicting a church by assembling blocks on the screen (Figure 5b).\n",
      "(no citation) Efficient space use.\n",
      "(no citation) Unfortunately, sometimes software can also be unreliable.\n",
      "(no citation) This indicates that merely perceiving information transparency was not able to promote users' cognitive control, but it did serve to enhance user trust directly.\n",
      "(no citation) In contrast, P5 had little experience with visualization, and compared to learning with graphic design tools: \"it takes 30 minutes for me to learn the [Data Illustrator] tutorial via a person, that usually to me is not an easy program.\n",
      "(no citation) With respect to the ambulatory setting, we learned that the exergames promoted the reinforcement and reestablishment of family relationships.\n",
      "(no citation) Parents should monitor there kids phones but I feel this app is to restrictive.\n",
      "(no citation) While our study provides evidence of the utility of our device combination for specific tasks, an in-depth study of open-ended visual exploration (cf.\n",
      "(no citation) This is interesting since the confidence interval visualization contains all the information necessary to compute the optimally weighted average--that is, it shows the sensor measurements and their associated variances.\n",
      "(no citation) They may be synchronous: daily standup meetings are a\r",
      "\r",
      "\r\n",
      "* - The work was performed while the author was at FXPAL\r",
      "\r",
      "\r\n",
      "\r",
      "\r",
      "\r\n",
      "Paper 170\r",
      "\r",
      "\r\n",
      "\r",
      "\r",
      "\r\n",
      "Page 1\r",
      "\r",
      "\r\n",
      "\r",
      "\r",
      "\r\n",
      "\f",
      "CHI 2018 Paper\r",
      "\r",
      "\r\n",
      "\r",
      "\r",
      "\r\n",
      "CHI 2018, April 21­26, 2018, Montréal, QC, Canada\r",
      "\r",
      "\r\n",
      "\r",
      "\r",
      "\r\n",
      "common practice among software development teams, particularly those who follow an agile process.\n",
      "(no citation) Any category with less than 2% representation or that had strong overlap with other categories were combined into other categories or eliminated.\n",
      "(no citation) In contrast, explanations of Expert Systems, Bayesian Networks, and Case-Base Reasoning influenced later research on explaining intelligent systems.\n",
      "(no citation) Our participants noted that the presence of a role model from a similar community/region as theirs would help them start a dialogue with their parents/partners about their independence and careers.\n",
      "(no citation) the pianist found that she was unable to get the system to follow her intended path the technical operator might have responded by nudging her along a particular path anyway (though in this case did not).\n",
      "(no citation) Furthermore, human annotators corrected 9,987 cooking actions the NLP tagger mislabeled.\n",
      "(no citation) We present this most frequently used frame (N=276, 34%) in more detail as we answer RQ1b.\n",
      "(no citation) The `high' level was chosen as the average level for high-level details plus one standard deviation, and likewise `low' was equal to the average for low-level details plus one standard deviation.\n",
      "(no citation) · We propose several implications and directions for future research in HCI towards achieving this goal.\n",
      "(no citation) CHI 2018, April 21­26, 2018, Montreal, QC, Canada © 2018 Copyright is held by the owner/author(s).\n",
      "(no citation) CONCLUSION Our analysis of how shopkeepers coped with demonetization gives descriptive insight into the nature of technology adoption in state-mandated decisions.\n",
      "(no citation) Our method focuses specifically on enabling access to diverse content within the music space but this approach is extensible to many other domains.\n",
      "(no citation) Sometimes I take the battery with me and charge it while I am at my garden.\n",
      "(no citation) Tests of fixed effects in two linear mixed models.\n"
     ]
    }
   ],
   "source": [
    "sample_neg = df[df.has_citation == 0].sample(50, random_state=0)\n",
    "print('\\n===\\nExample sentences without citations:')\n",
    "\n",
    "for i, row in sample_neg.iterrows():\n",
    "    print('(no citation)', row['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-325aecde99d9>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0msample_pos\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhas_citation\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msample\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m50\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'\\n===\\nExample sentences with citations:'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrow\u001b[0m \u001b[1;32min\u001b[0m \u001b[0msample_pos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miterrows\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Raw text:'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrow\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'text'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrow\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'has_citation'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'df' is not defined"
     ]
    }
   ],
   "source": [
    "sample_pos = df[df.has_citation == 1].sample(50, random_state=0)\n",
    "print('\\n===\\nExample sentences with citations:')\n",
    "for i, row in sample_pos.iterrows():\n",
    "    print('Raw text:', row['text'])\n",
    "    print(row['has_citation'])\n",
    "    print('Processed text:', row['processed_text'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Cleaning\n",
    "This section provides a careful walk-through of our data cleaning process. In particular, it focuses on justifying each step and providing examples.\n",
    "\n",
    "Broadly, there are 4 issues (in order of execution, not importance)\n",
    "1. Tokenizing academic text\n",
    "2. Finding and \"disposing\" of citations cleanly\n",
    "3. Finding and removing reference sections\n",
    "4. Dealing with artifacts of PDF conversion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tokenizing text from academic PDF files\n",
    "Academic text includes frequent use of the period character in ways that are not handled well by NLTK's default sentence tokenizer. Therefore, we simply replace common academic expressions with an equivalent (albeit grammatically incorrect) version without periods.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['This sentence is quite academic, ie it belongs in an academic paper (eg a conference paper).', 'We show in Fig 1 that our work is important, which supports the findings of Smith et al among others.']\n"
     ]
    }
   ],
   "source": [
    "from nltk import tokenize\n",
    "\n",
    "data = \"This sentence is quite academic, i.e. it belongs in an academic paper (e.g. a conference paper). \\\n",
    "We show in Fig. 1 that our work is important, which supports the findings of Smith et al. among others.\"\n",
    "\n",
    "pairs = {\n",
    "    'Fig.': 'Fig',\n",
    "    'e.g.': 'eg',\n",
    "    'i.e.': 'ie',\n",
    "    'et al.': 'et al',\n",
    "}\n",
    "for key, val in pairs.items():\n",
    "    data = data.replace(key, val)\n",
    "sentences = tokenize.sent_tokenize(data)\n",
    "print(sentences)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Finding and \"disposing\" of citations cleanly\n",
    "To even beging generating labels for our machine learning task, we need to generate labels that indicate which sentences have citations. However, if we don't \"dispose\" of the citation markers in the training data (e.g. bracketed citations like [1] or [34,35]) our training data won't generalize at all to real data. Most obviously, a character-based model might just learn to label all sentences with a bracket character as having citation. However, less obvious issues may occur: for example, we found after stripping away the [1], we might be left with odd-looking text, such as a comma surrounding by whitespace.\n",
    "\n",
    "`\"...Smith et al. showed this [1], and therefore...\" -> \"Smith et al. showed this , and therefore...\"`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Finding and removing reference sections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
