{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Citation Needed? Detecting Sentences from Computing Research Papers that Need Citations\n",
    "Author: Nicholas Vincent, Northwestern University\n",
    "\n",
    "email: nickvincent@u.northwestern.edu | lab website: [www.psagroup.org](http://www.psagroup.org) | personal website: [www.nickmvincent.com](http://www.nickmvincent.com)\n",
    "\n",
    "Prof. Doug Downey's EECS349 course, final project\n",
    "\n",
    "## Abstract: \n",
    "The scientific paper is the primary artifact produced by scientists of every discipline. Within a scientific paper, citations are incredibly valuable: they help connect a paper to the surrounding literature, provide evidence for claims, and empower a single 10-page PDF to “stand on the shoulders of giants” by referencing prior work. However, language is ambiguous, and it may not always be trivial to decide whether a certain sentence should include a citation or not.  Therefore, it may be valuable for an author or reviewer to be able to quickly identify whether a sentence should include a citation or not. We implement and test a variety of machine learning classifiers that attempt to solve this task.\n",
    "\n",
    "In this work, we explore two distinct approaches to classification: (1) using word-level features (i.e. bag-of-words) alongside textual metadata with traditional classification techniques (Naive Bayes, trees, logistic regression, etc) and (2) using character-level features with a deep learning techniques (recurrent neural networks, long-short term memory). We find that for a small dataset (every sentence from 20 computing research papers) logistic regression performs the best.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Dataset\n",
    "#### Data Aquisition\n",
    "We generated all training and test data by downloading computing papers as PDF and converting them to text (detailed below). Each text file was processed so as to split the text into sentences (using NLTK sentence tokenizer with some domain-specific tweaks), identify all the sentences with citations, and then strip out the evidence of the citations (in the case papers we used, this was bracketed numbers, like [1]) so the data could be fairly for training.\n",
    "\n",
    "We built two datasets for developing and testing: first we used a \"small\" dataset composed of X papers. This dataset included X different sentences and 11% (X) had citations. The papers for this dataset came exclusively from the PSA Research Group (the author's research lab), so this dataset is appropriate for including example sentences.\n",
    "\n",
    "### Iterating on Data Cleaning\n",
    "\n",
    "\n",
    "## Overview of Features and Classification Approaches Used\n",
    "\n",
    "## Results\n",
    "We found that...\n",
    "\n",
    "## Future Work\n",
    "Although...\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Appendix\n",
    "Example data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Raw text: Other areas with a strong female focus include modeling and womens' sports. {{no citation}}\n",
      "Raw text: To test our developed algorithm, which we describe in detail below, we used three distinct test data sets with multiple pSUR and their corresponding PTARGET polygons. {{no citation}}\n",
      "Raw text: So you have to say it like this is a restaurant with rooms available or something like that. {{no citation}}\n",
      "Raw text: We performed this computation three times: once under the localness assumption (in which we did no filtering for non-local tweets), once filtering out non-local tweets using n-days and once doing the same with\r",
      "\r",
      "\r\n",
      "\r",
      "\r",
      "\r\n",
      "4 https://github.com/andyreagan/labMT-simple\r",
      "\r",
      "\r\n",
      "\r",
      "\r",
      "\r\n",
      "plurality5. {{no citation}}\n",
      "Raw text: The coders overlapped on tokens for 5 articles and achieved a relatively good Cohen's  = 0.69. {{no citation}}\n",
      "Raw text: 1, No. {{no citation}}\n",
      "Raw text: In addition, we show that the geographic contours of localness follow important sociodemographic trends, with social media in, for instance, rural areas and older areas, being substantially less local in character (when controlling for other demographics). {{no citation}}\n",
      "Raw text: An aware guest will be able to sense if this is the case according to Participant 9:\r",
      "\r",
      "\r\n",
      "As a guest you definitely need to feel the [host's] personality. {{no citation}}\n",
      "Raw text: The case studies of Wikipedia articles require no additional mapping. {{no citation}}\n",
      "Raw text: To operationalize content diversity, we use a metric we call Outlink Entropy, which has the advantage of being directly linked to the diversity of commonly-used \"bag of links\" models as well as capturing a human-visible notion of content diversity. {{no citation}}\n",
      "Raw text: Therefore, we draw upon wellestablished causal inference methods (eg [26,44]) that estimate the loss in value that would occur to these communities if posts with Wikipedia links were replaced with a range of alternatives (ie counterfactuals).\n",
      "1.0\n",
      "Processed text: Therefore, we draw upon wellestablished causal inference methods (eg ) that estimate the loss in value that would occur to these communities if posts with Wikipedia links were replaced with a range of alternatives (ie counterfactuals).\n",
      "Raw text: These biases are nearly always demographically linked, providing advantages for alreadyadvantaged demographics (eg [18,29,30,48]).\n",
      "1.0\n",
      "Processed text: These biases are nearly always demographically linked, providing advantages for alreadyadvantaged demographics (eg ).\n",
      "Raw text: For instance, Chess [6] highlights that Ingress players become both more active in their local physical space, but at the same time become part of the global virtual game space.\n",
      "1.0\n",
      "Processed text: For instance, Chess  highlights that Ingress players become both more active in their local physical space, but at the same time become part of the global virtual game space.\n",
      "Raw text: As of July 2017, Reddit is the ninth-most-visited website globally [63], has 300M monthly visitors, and has a $1.8B valuation [64].\n",
      "1.0\n",
      "Processed text: As of July 2017, Reddit is the ninth-most-visited website globally , has 300M monthly visitors, and has a $1.8B valuation .\n",
      "Raw text: [30] OSM's structured data creation occurs in its tagging infrastructure, which lets editors specify the semantics of a geospatial entity using key-value pairs (eg its name, whether it is a restaurant or a hospital, etc.).\n",
      "1.0\n",
      "Processed text:  OSM's structured data creation occurs in its tagging infrastructure, which lets editors specify the semantics of a geospatial entity using key-value pairs (eg its name, whether it is a restaurant or a hospital, etc.).\n",
      "Raw text: As is well-known in the human computation domain, crowdsourced data is subject to quality issues such as spam, errors, and biases [12].\n",
      "1.0\n",
      "Processed text: As is well-known in the human computation domain, crowdsourced data is subject to quality issues such as spam, errors, and biases .\n",
      "Raw text: Much of this research has focused on comparing OSM spatial entities to ground truth data (eg [5,6,21]).\n",
      "1.0\n",
      "Processed text: Much of this research has focused on comparing OSM spatial entities to ground truth data (eg ).\n",
      "Raw text: Second, we used wikification [33] to extract each mention of an article within Wikipedia -- whether or not it was hyperlinked.\n",
      "1.0\n",
      "Processed text: Second, we used wikification  to extract each mention of an article within Wikipedia -- whether or not it was hyperlinked.\n",
      "Raw text: In addition to the preference for fewer turns, increased route complexity also raises safety concerns [33] and has been directly tied to greater cognitive loads [36] and stress [56] for the driver.\n",
      "1.0\n",
      "Processed text: In addition to the preference for fewer turns, increased route complexity also raises safety concerns  and has been directly tied to greater cognitive loads  and stress  for the driver.\n",
      "Raw text: Algorithmic Accountability Our research builds on the growing literature on algorithmic accountability (eg, [2,56,57]), in which algorithms are probed for discrimination or other societally undesirable outcomes.\n",
      "1.0\n",
      "Processed text: Algorithmic Accountability Our research builds on the growing literature on algorithmic accountability (eg, ), in which algorithms are probed for discrimination or other societally undesirable outcomes.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv('all_labeled_sentences.csv', encoding='utf8')\n",
    "\n",
    "sample_neg = df[df.has_citation == 0].sample(10)\n",
    "for i, row in sample_neg.iterrows():\n",
    "    print('Raw text:', row['text'], '{{no citation}}')\n",
    "        \n",
    "sample_pos = df[df.has_citation == 1].sample(10)\n",
    "for i, row in sample_pos.iterrows():\n",
    "    print('Raw text:', row['text'])\n",
    "    print(row['has_citation'])\n",
    "    print('Processed text:', row['processed_text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
